{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0b39fa2-cf21-4add-9aea-c389fa295f4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Describe the significance of scalable models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56baee1c-df3d-495b-8bd7-35c8c8fd93a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## What is enterprise or large-scale data?\n",
    "Before we talk through scalability, let's define what we're talking about. You'll see throughout the module that we refer to **_enterprise-scale_** or **_large-scale_** data rather than big data. In this module, enterprise-scale or large-scale data refers to tables with a large number of records or rows. Power BI, used with tools like Azure Synapse Analytics, can analyze massive datasets, in the range of trillions of rows or petabytes of data.\n",
    "\n",
    "If you're familiar with working with enterprise data, it may be helpful to understand that Power BI is the next generation of Analysis Services. It's the same technology under the hood of Analysis Services and Power BI datasets, the [VertiPaq engine](https://learn.microsoft.com/en-us/analysis-services/analysis-services-overview?view=asallproducts-allversions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc772ae3-f739-403d-af74-cf87d576fada",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## What is scalability and why is it important?\n",
    "Scalability in this context refers to building data models that can handle growth in the volume of data. A data model that ingests thousands of rows of data may grow to millions of rows over time, and the model must be designed to accommodate such growth. It's important to consider that your data will grow and/or change, which increases complexity.\n",
    "\n",
    "Scalability must be at the forefront in enterprise solutions to ensure:\n",
    "- Flexibility - models need to be able to accommodate change\n",
    "- Data growth - models must be able to handle an increase in data volume with acceptable report performance\n",
    "- Reduced complexity - models built with scalability in mind will be less complex and easier to manage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fa71f02-69b9-44ba-a96d-d4d9d77b26fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## How do I design for scalability?\n",
    "The best approach to building scalable Power BI data models will always be building with data modeling best practices in mind.\n",
    "\n",
    "Beyond the data model, [Power BI Premium](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-what-is) was designed specifically for enterprise deployments. Premium capacity offers greater storage capacity and allows for larger individual datasets depending on the [SKU](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-what-is#size-considerations). Implementing the premium only large dataset storage feature enables data to grow beyond the Power BI desktop (.pbix) file size limitations.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Are you planning a Power BI enterprise deployment? Read the [Power BI enterprise deployment whitepaper](https://aka.ms/PBIEnterpriseDeploymentWP) for a full list of enterprise deployment considerations.\n",
    "\n",
    "Another important consideration in designing for scalability using Power BI Premium is [choosing the right capacity](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-what-is#capacity-nodes). You'll need to work with your Power BI administrator to determine which Power BI Premium licensing SKU is available to you. If you're having performance issues in Premium capacity, work first to optimize your model, and then work with your Power BI administrator to [monitor Power BI Premium capacities](https://learn.microsoft.com/en-us/power-bi/enterprise/service-admin-premium-monitor-capacity).\n",
    "\n",
    "At the most basic level, it's important to understand that Premium capacities require sufficient memory for processing. You'll need to double the amount of RAM to process your data model refresh. For example, if you have a 40-GB dataset, you'll need **_at least_** 80-GB of memory available. A 40-GB dataset would be best supported by a P3/A6 capacity, which contains 100-GB of memory.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Review [Power BI license types and capabilities](https://learn.microsoft.com/en-us/power-bi/enterprise/service-admin-licensing-organization#license-types-and-capabilities). If you're not sure which license type your organization has, check with the Power BI administrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c7f2fb4-63f5-4683-a35f-2d2f74bd4bc9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Implement Power BI data modeling best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "868c9cf4-12aa-4724-9e76-5cb555e2765f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Choose the correct Power BI model framework\n",
    "Choosing the correct Power BI model framework is at the heart of building any scalable solution.\n",
    "\n",
    "The first place to start with your Power BI data model is [import mode](https://learn.microsoft.com/en-us/power-bi/connect-data/service-dataset-modes-understand#import-mode). Import mode offers you the most options, design flexibility, and delivers fast performance.\n",
    "\n",
    "Use [DirectQuery](https://learn.microsoft.com/en-us/power-bi/connect-data/service-dataset-modes-understand#directquery-mode) when your data source stores large volumes of data and/or your report needs to deliver near real-time data.\n",
    "\n",
    "Finally, use a [composite model](https://learn.microsoft.com/en-us/power-bi/connect-data/service-dataset-modes-understand#composite-mode) when you need to:\n",
    "- Boost the query performance of a DirectQuery model.\n",
    "- Deliver near real-time query results from an import model.\n",
    "- Extend a Power BI dataset (or Azure Analysis Services model) with other data.\n",
    "\n",
    "Composite models combine data from more than one DirectQuery source or combine DirectQuery with import data.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Review the [Choose a Power BI model framework module](https://learn.microsoft.com/en-us/training/modules/choose-power-bi-model-framework/) for more information on using import, DirectQuery, or composite models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968dfa75-1a6b-4e5b-87ed-9c39e9e46f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Implement data modeling best practices\n",
    "There are some basic principles to abide by when building any data model. These principles become even more important as data begins to grow.\n",
    "\n",
    "Most importantly, you want to do as much data preparation work as possible **before data reaches Power BI**, as far upstream as possible. For example, if you have the opportunity to transform data in the data warehouse, that's where it should be done. Transformation at the source produces consistency for any other solutions built on that data and ensures that your Power BI model doesn't need to do any extra processing. This may require working with your data engineer or other members of the data team and is critically important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5698ebc6-af02-42e2-9cd9-b42b414e3b3c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Best practices for import mode:\n",
    "- Always **start with import mode** if you can.\n",
    "- **Only bring in data you need**.\n",
    "  - Remove unnecessary rows and columns.\n",
    "  - Only process what is absolutely necessary (tables/partitions) given the business requirements.\n",
    "- **Avoid wide tables**.\n",
    "  - Use a [star schema](https://learn.microsoft.com/en-us/power-bi/guidance/star-schema) in Power BI.\n",
    "    - If your source is a beautifully modeled data warehouse, you're a step ahead.\n",
    "    - Big data is often in wide flat tables. Take advantage of dimensional models for their performance benefits.\n",
    "    - Power BI supports multiple fact tables with different dimensionality and different granularities – you don’t have to put everything into one large table.\n",
    "- **Pre-aggregate data before loading it to the model** where possible.\n",
    "- **Reduce the usage of calculated columns**.\n",
    "  - Data transformations requiring additional columns should be done as close to the source as possible.\n",
    "- **Avoid high cardinality columns**.\n",
    "  - Consider breaking a datetime column into two columns, one for date and one for time.\n",
    "- **Use appropriate data types**.\n",
    "  - Use integers instead of strings for ID columns.\n",
    "  - Use surrogate keys for ID columns if necessary.\n",
    "- **Limit the use of bi-directional filters** on relationships.\n",
    "- **Disable [auto date/time](https://learn.microsoft.com/en-us/power-bi/guidance/auto-date-time)**.\n",
    "  - Connect to a date table at the source or create your own date table.\n",
    "- Disable attribute hierarchies for non-attribute columns.\n",
    "- If querying a relational database, **query database views rather than tables**.\n",
    "  - A view provides an abstraction layer to manage columns, and relates back to the first consideration, pushing - transformations as close to the source as possible.\n",
    "  - Views shouldn't contain logic. They should only contain a SELECT statement from a table.\n",
    "- **Consider partitioning and incremental refresh** to avoid loading data you don’t need to.\n",
    "- Check to ensure [query folding](https://learn.microsoft.com/en-us/power-query/power-query-folding) is achieved.\n",
    "  - If query folding isn't possible, you have another opportunity to work with the data engineer to move transformation upstream.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\">  Learn more about [techniques to help reduce the data loaded into import models](https://learn.microsoft.com/en-us/power-bi/guidance/import-modeling-data-reduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e366e42d-6e71-4d88-a53c-3591b44c7a52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Best practices specific to DirectQuery mode:\n",
    "- Set relationships to enforce integrity using the [Assume referential integrity property](https://learn.microsoft.com/en-us/power-bi/connect-data/desktop-assume-referential-integrity) on relationships.\n",
    "  - The Assume Referential Integrity setting on relationships enables queries to use INNER JOIN statements rather than OUTER JOIN.\n",
    "- **Limit the use of bi-directional filters** on relationships.\n",
    "- Use only when necessary.\n",
    "- Limit the **complexity of DAX calculations**.\n",
    "  - Because query folding occurs by default in DirectQuery, more complex DAX measures means added complexity at the source, leading to slow queries.\n",
    "  - The need for complex DAX also leads back to the key principle of applying transformations as far upstream as possible. You may need to work with the data engineer to apply transformations at the source.\n",
    "- **Avoid the use of calculated columns**.\n",
    "  - Transformations requiring additional columns should be done as far upstream as possible, particularly when using DirectQuery.\n",
    "- **Avoid relationships on calculated columns**\n",
    "- **Avoid relationships on Unique Identifier columns**\n",
    "- Use **dual storage mode** for dimensions related to fact tables that are in DirectQuery.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Refer to the [DirectQuery model guidance](https://learn.microsoft.com/en-us/power-bi/guidance/directquery-model-guidance) for a complete list of considerations in developing DirectQuery models.\n",
    "\n",
    "There's also a tool you can use as you're developing tabular models that will alert you of modeling missteps or changes that would improve model design and performance. The [Best Practice Analyzer within Tabular Editor](https://powerbi.microsoft.com/blog/best-practice-rules-to-improve-your-models-performance/) was designed to help you design models that adhere to modeling best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f77ce791-a2ed-4150-b413-82380de3d6c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Configure large datasets\n",
    "Power BI datasets store data in a highly compressed, in-memory cache for optimized query performance. Enterprise deployment of an analytics solution using Power BI will likely require [Power BI Premium](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-what-is). With the **_large dataset storage format_** enabled, dataset sizes are limited only by the capacity size, or a maximum size set by the administrator. This differs from datasets in Power BI Premium, which are limited to 10 GB after compression if large dataset storage format isn't enabled.\n",
    "\n",
    "Large datasets can be enabled for all Premium P SKUs, Embedded A SKUs, and with Premium Per User (PPU). The large dataset size limit in Premium is comparable to Azure Analysis Services, in terms of data model size limitations.\n",
    "\n",
    "The large dataset feature brings the Power BI dataset cache sizes to parity with Azure Analysis Services model sizes. The large dataset feature enables consolidation of tabular models from SQL Server Analysis Services and Azure Analysis Services on one common platform based on Power BI Premium.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> To use large dataset storage format, the dataset must be stored in a workspace that allocated to Premium capacity.\n",
    "\n",
    "Enabling the large dataset format enables fast user interactivity and allows data to grow beyond the 10-GB limit. Additionally, the large dataset format can also improve xmla write operation performance, even for datasets that may not be large.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Datasets enabled for large models can't be downloaded as a Power BI Desktop (.pbix) file from the Power BI service. Read more about [.pbix download limitations](https://learn.microsoft.com/en-us/power-bi/create-reports/service-export-to-pbix#limitations-when-downloading-a-pbix-from-a-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "654e5c15-dd0a-433a-887f-fde4bf703b98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Enable large dataset storage format\n",
    "To take advantage of the large dataset storage format option, it must be enabled in the Power BI service. Here you can enable large dataset storage format for a single dataset, or for all datasets created in a workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a85353e-9058-4892-b717-3fe4614c39bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Enable large dataset storage format for a single dataset\n",
    "In the dataset settings in the Power BI service, toggle the slider to on and select **Apply**.\n",
    "\n",
    "<img src=\"../images/05_Work with semantic models in Microsoft Fabric/01/enable-large-dataset.png\" alt=\"Screenshot of the large dataset storage format option in the dataset settings in the Power B I service, with the toggle in the on position.\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56a1ee97-09e2-4c6c-b657-b18c08bd9a25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Enable large dataset storage format for all datasets created in a workspace\n",
    "You can set the default storage format for all datasets created in a workspace in the workspace settings. In the settings, select **_Premium_**, and select **_Large dataset storage format_** as the **_Default storage format_**.\n",
    "\n",
    "<img src=\"../images/05_Work with semantic models in Microsoft Fabric/01/default-storage-format.png\" alt=\"Screenshot of the premium workspace settings in the Power B I service, with the cursor over the large dataset storage format option.\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "Large dataset storage format for a workspace can also be enabled using PowerShell.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> See [Configure large datasets](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-large-models) to learn more about large models in Power BI Premium including information on checking dataset size, dataset eviction, considerations, and limitations."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Understand scalability in Power BI",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
