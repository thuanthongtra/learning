{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d25dde8-3813-4656-b7bf-74c63b1ebdcc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Describe Microsoft Fabric Real-Time Intelligence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74dc907a-3386-406b-8217-95b6fcd0375e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Real-Time Intelligence\n",
    "**Real-Time Intelligence** is a fully managed service that is optimized for **`streaming time-series` data**. \n",
    "\n",
    "By Using Real-Time Intelligence in Fabric, you can:\n",
    "- **_Ingest_** data from **any `source`**, in **any `data format`**.\n",
    "- **_Import_** data with **by-default `streaming`** that provides high performance, low latency, high freshness data analysis.\n",
    "- Imported data **_undergoes_** **default `partitioning`** - both **`time` and `hash-based`** partitioning, and **by-default `indexing`**.\n",
    "- **_Work_** with **versatile `data structures`** and query structured, semi-structured, or free text.\n",
    "- **_Run_** analytical queries **directly on `raw` data** without the need to build complex data models or create scripting to transform the data.\n",
    "- **_Query_** raw data without transformation, with high performance, incredibly low response time, and using a wide variety of available operators.\n",
    "- **_Scale_** to an **unlimited amount of data**, from **`gigabytes to petabytes`**, with unlimited scale on **_concurrent queries_** and **_concurrent users_**.\n",
    "- **_Integrate_** seamlessly with **other _workloads_ and _items_** in Microsoft Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c060d0c4-6694-412a-a115-282d74dfb8cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Real-Time Hub\n",
    "The **Real-Time Hub** serves as your **_gateway_** to **`uncover`** and **`control`** the flow of your streaming data. It's a dynamic catalog that includes:\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/real-time-hub-highlight.png\" alt=\"Real-Time hub\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc5de3b2-739a-4dad-8602-7a235d3fd5f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Real-Time Dashboards\n",
    "Data insights can be visualized through **`KQL querysets`**, **`Real-Time dashboards`**, and **`Power BI`** reports, with a rapid transition from data ingestion to visualization.\n",
    "- Users can employ visual cues for **_filtering_** and **_aggregating_** query results, **_utilizing_** a comprehensive suite of built-in visualizations, with minimal coding. \n",
    "- Insights are accessible in Power BI Reports and Real-Time Dashboards, both of which can **incorporate `alerts`** based on the data insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "417885f2-ff97-4f5a-b95d-fc488d289f34",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Alerts\n",
    "**Alerts** can also be set within the non-table visualizations on the Real-Time Dashboards while in editing mode to **_provide notifications_** when an established threshold that you set has been met.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/set-alert-dashboard.png\" alt=\"Real-Time Dashboard alerts\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "The alerts can notify you within **`Microsoft Teams`** or by **sending an `email`**.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/set-alert-parameters.png\" alt=\"Alert parameter configuration\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81cd079c-0add-4eee-bd9c-c39be0919969",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Understand KQL database and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f61463c-9920-45c2-9171-4961ef1d1953",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Kusto Query Language (KQL)\n",
    "**Kusto Query Language (KQL):** is a **_declarative query language_** used to analyze and extract insights from structured, semi-structured, and unstructured data.\n",
    "- It was designed specifically for searching large-scale **`log data`** efficiently and quickly, making it perfectly suited for cloud-based data analytics.\n",
    "- It enables **efficiency in data exploration and data analysis** by allowing users to work with **_heterogeneous data sources_** and visualize the results in various ways.\n",
    "- It supports **reproducible analyses** by allowing users to create **_notebooks with_ `Kusto kernel`** that can capture code, results, and context on the analysis.\n",
    "- It improves **DevOps troubleshooting experience** by allowing users to create **`runbooks`** or **`playbooks`** in notebooks with Kusto kernel that can detail how to troubleshoot and mitigate issues using telemetry data.\n",
    "- It enriches **DevOps flow** by allowing users to add KQL files and KQL notebook files to their Git repositories and CI/CD pipelines.\n",
    "- It provides **guidance and helps you build search queries from scratch** by using the KQL editor that **quickly identifies `potential errors`** and **displays `hints`** about how to resolve issues.\n",
    "- It lets you quickly **paste long, complex queries directly into the editor** if you receive them from other sources.\n",
    "- It allows you to **filter, present, and aggregate your data** using various operators and functions that are easy to read and author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e29ad25c-1468-4f7b-be61-cb6d05378596",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Real-Time Intelligence core components\n",
    "Screenshot of Fabric Real-Time Intelligence components.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/real-time-intelligence-core-components.png\" alt=\"Fabric Real-Time Intelligence components\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "**1. Event house:** Event houses are like a large, efficient **`library` for data**. They help organizations handle and analyze lots of data quickly, especially when it's important to get insights fast. Think of it as a supercharged database that can deal with data coming in nonstop, from different places, and in various forms. It's designed to grow with the data needs of a project, making sure everything will run smoothly without wasting resources.\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/eventhouse-landing-page-large.png\" alt=\"Event house landing page\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "**2. KQL database:** is a Kusto database and an upper-level entity that hosts a collection of tables, stored functions, materialized views, shortcuts, and datastreams.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> You can continue to create and use stand-alone KQL databases while event house is still in preview. After this period, they will be managed with the event house as the management layer hosting many KQL databases.\n",
    "\n",
    "**3. KQL Queryset:** Use this tool to **run queries**, and **view** and **manipulate query results** on data from your KQL database. The KQL Queryset allows you to save queries for future use, or export and share queries with others. In addition, the KQL Queryset uses the Kusto Query language for query creation, and also supports T-SQL and some T-SQL functions. For more information about the query language, see [Kusto Query Language overview](https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/?branch=release-public-preview).\n",
    "\n",
    "**4. Real-Time Dashboards:** to understand these, imagine a dashboard as a customizable control panel on your computer or game console.\n",
    "- Each section, or \"tile,\" shows you different information, like your score, health level, or map in a game. \n",
    "  - These tiles are set up to show specific data and can be arranged in different pages to keep things organized. Just like you can change settings in a game. \n",
    "  - You can tweak these tiles to show different data or look different visually. It's like having a bunch of mini-screens, each showing you something useful, and you can export complex data queries from Kusto Query Language (KQL) directly into these tiles as visuals.\n",
    "  - It's like having a high-performance gaming rig that lets you switch between screens and data without lag, giving you a smooth and integrated experience.\n",
    "\n",
    "**5. Eventstream:** Think of event streams in Microsoft Fabric as a super handy tool that lets you **_handle_ live data `without any coding`**. \n",
    "- It's like a high-tech funnel that **`collects`**, **`changes`**, and **`sends`** data to different places automatically. \n",
    "  - When you set up an eventstream in the system, you're basically creating a mini-factory that processes real-time data. You tell it where to get data from, where to send it, and how to change it along the way if needed. \n",
    "- It's part of a bigger feature called **`Real-Time Intelligence`**, which is all about making sense of data as it happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e36d314e-8d75-4bc5-878f-a61caf7a101c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## KQL Database objects\n",
    "As with many databases, the KQL Database has many objects to handle your data storage, streaming, and querying needs to support your decision making systems downstream. From the event house landing page, you can select on any of the databases and navigate to the individual database for exploring data, adding elements, and more.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/kql-database-landing.png\" alt=\"KQL Database landing page\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "- **A table:** is a schema entity that contains a **set of columns and rows** of data. A table has a well-defined schema (an ordered list of column name and data type pairs). You can use the `.create table` command to create a new table, the `.show table` command to show the table schema, and the `.ingest` command to ingest data into a table.\n",
    "- **A function:** is a schema entity that encapsulates a **subquery expression** that can be invoked from within other KQL queries. A stored function has a name, an optional list of parameters, and a body that contains the subquery expression. You can use the `.create function` command to create a new stored function, and the `.show functions` command to show the stored functions in a database.\n",
    "- **A materialized view:** is a schema entity that stores **precomputed results** of a query for faster retrieval. A materialized view has a name, an optional list of parameters, and a body that contains the query expression. You can use the `.create materialized-view` command to create a new materialized view, and the `.show materialized-views` command to show the materialized views in a database.\n",
    "- **A datastream:** is a representation of all of the **attached KQL eventstream** connected to the KQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "555bc91a-a8c5-49df-be50-794c36e0d8d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Describe Microsoft Fabric Real-Time hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57fbc2e6-ed18-4ee0-a293-9604d898898c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Getting data into the Real-Time hub\n",
    "The Real-Time Hub serves as your gateway to uncover and control the flow of your streaming data. It's a dynamic catalog that includes:\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/real-time-hub-highlight.png\" alt=\"Real-Time hub role\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "- **Event streams:** Gain access to all the active event streams within Fabric that you're permitted to view.\n",
    "- **Microsoft Sources:** Quickly find and configure streaming sources available to you, such as Azure Event Hubs, Azure IoT Hub, and various Change Data Capture (CDC) options from Azure SQL DB, Azure Cosmos DB, and PostgreSQL DB.\n",
    "- **Fabric Events:** Use event-driven features for instant notifications and data handling. Keep tabs on events from Fabric Workspace Items to Azure Blob Storage, which can initiate further processes or workflows. This action could involve starting a data pipeline or dispatching an email alert. Plus, you have the flexibility to route these events to different destinations through Event streams. Alerts allow you to interact both within your workspace and outside of it from the Real-Time hub by selecting the <img src=\"../images/01_Get started with Microsoft Fabric/08/set-alert-button.png\" alt=\"Real-Time hub role\">  **_Set alert_** button.\n",
    "\n",
    "All this information is presented in an easy-to-digest format, ensuring seamless integration with your Fabric workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "733fc32e-f562-4e87-b6e2-1327a8caf3af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Source the event stream\n",
    "The Microsoft Fabric Real-Time Intelligence experience's event streams feature allows for seamless integration of real-time events into Fabric. You can create an eventstream, which is an instance within Fabric, add sources of event data, apply optional transformations to the data, and route it to various destinations, all without the need for coding. This no-code approach simplifies the process of managing event data within Fabric.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/event-stream-sources.png\" alt=\"Event stream sources\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f4442bc-13e8-4524-b894-2a69e83a052e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Processing events within event streams\n",
    "The drag and drop interface offers a straightforward and user-friendly method for constructing your event data workflows. This includes processing, transformation, and routing, all without the need for coding. An eventstream's data flow diagram provides a clear visual representation of the data's journey and structure. Additionally, the event processor editor's no-code environment enables you to design your event data processing logic simply by dragging and dropping elements into place.\n",
    "\n",
    "- **Transformation Description:** When you create an eventstream with Enhanced capabilities enabled, all destinations support transformation operations. Without Enhanced capabilities, transformations are only available for Lakehouse and KQL Database destinations, which handle event processing before ingestion.\n",
    "\n",
    "- **Filter:** Use the Filter transformation to filter events based on the value of a field in the input. Depending on the data type (number or text), the transformation keeps the values that match the selected condition, such as is `null` or `is not null`.\n",
    "- **Manage fields:** This transformation allows you to add, remove, change data type, or rename fields coming in from an input or another transformation.\n",
    "- **Aggregate:** Use the Aggregate transformation to calculate an aggregation (Sum, Minimum, Maximum, or Average) every time a new event occurs over a period of time. This operation also allows for the renaming of these calculated columns, and filtering or slicing the aggregation based on other dimensions in your data. You can have one or more aggregations in the same transformation.\n",
    "- **Group by:** Use the Group by transformation to calculate aggregations across all events within a certain time window. You can group by the values in one or more fields. It's like the Aggregate transformation allows for the renaming of columns, but provides more options for aggregation and includes more complex options for time windows. Like Aggregate, you can add more than one aggregation per transformation.\n",
    "- **Union:** Use the Union transformation to connect two or more nodes and add events with shared fields (with the same name and data type) into one table. Fields that don't match are dropped and not included in the output.\n",
    "- **Expand:** Use this array transformation to create a new row for each value within an array.\n",
    "- **Join:** this is a transformation to combine data from two streams based on a matching condition between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a74615f-47ef-40d1-9ba8-a1c494b58755",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Standard destination locations\n",
    "We can see that by not choosing the enhanced capabilities, our destinations are limited.\n",
    "\n",
    "| Destination\t| Description |\n",
    "| -- | -- |\n",
    "| Custom app\t| With this feature, you can seamlessly direct your real-time event traffic to a bespoke application. It enables the integration of your proprietary applications with the event stream, allowing for the immediate consumption of event data. This feature is advantageous when you aim to transfer real-time data to an independent system not hosted on the Microsoft Fabric. |\n",
    "| Lakehouse\t| This destination empowers you to preprocess your real-time events prior to their ingestion into your lakehouse. The events are transformed into Delta Lake format and later stored in specific lakehouse tables, facilitating your data warehousing needs. For detailed guidance on utilizing the event processor for real-time data handling, refer to the 'Process event data with event processor editor' section. |\n",
    "| KQL database\t| This destination offers the capability to funnel your real-time event data into a KQL database, granting you the power to employ the robust Kusto Query Language (KQL) for data interrogation and analysis. Housing your data within the KQL database unlocks the potential for enhanced comprehension of your event data and the creation of comprehensive reports and dashboards. You have the flexibility to opt for one of two data ingestion approaches: either direct ingestion or preprocessing of events prior to ingestion. |\n",
    "| Reflex\t| This destination facilitates a direct linkage of your real-time event data with a Reflex. A Reflex is an intelligent entity equipped with all necessary details to establish data connections, monitor specific conditions, and execute actions. Upon the event data meeting certain predefined criteria or identifying particular patterns, the Reflex autonomously initiates suitable responses, such as notifying users or triggering Power Automate workflows. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0cb1d32-a1c9-4a94-b9c7-12c9b153c79a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Enhanced destination locations\n",
    "When you choose the enhanced capabilities, you're able to use the standard destinations along with **_derived stream_**.\n",
    "\n",
    "| Destination\t| Description |\n",
    "|-- |-- |\n",
    "| Derived stream\t| The derived stream is a specialized destination created post-application of stream operations like Filter or Manage Fields to an eventstream. It represents the altered default stream after processing, which can be routed to various destinations within Fabric and monitored in the Real-Time hub. |\n",
    "\n",
    "You're now able to attach to multiple destinations within an event stream at the same time without impacting or colliding with each other.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/real-time-events-workflow.png\" alt=\"Simultaneous event streams\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6474041-ba9c-4f9c-b6ab-ab49f19e0499",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Write queries with KQL\n",
    "To query data from a table in a KQL database, you can use the **Kusto Query Language (KQL)**, which is used to write queries in Azure Data Explorer, Azure Monitor Log Analytics, Azure Sentinel, and Microsoft Fabric. KQL is a read-only request to process data and return results. KQL queries are made of one or more query statements.\n",
    "\n",
    "A query statement consists of a table name followed by one or more operators that take, `filter`, `transform`, `aggregate`, or `join` data. For example:\n",
    "\n",
    "KQL queries are created using relational operators to filter and transform data using a syntax similar to SQL. However, KQL syntax includes extensions that enable advanced text and pattern matching, statistical analysis, time-series projections, geo-spatial, and machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a15b635d-eaf9-4c44-a367-693007f63c52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create and load tables in KQL\n",
    "In most cases, you create tables and define their source using the graphical tools in Microsoft Fabric. However, you can use KQL statements to create and load tables.\n",
    "\n",
    "To create a table and ingest data into it, you can use the `.create table` command, which creates a new empty table with a specified schema. You need to provide the table name, the column names and their data types, and optionally some properties such as docstring or folder. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0efe7749-7f39-4c5c-94c7-bece746c8c1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --Kusto\n",
    ".create table sales (\n",
    "     SalesOrderNumber: string,\n",
    "     SalesOrderLineItem: int,\n",
    "     OrderDate: datetime,\n",
    "     CustomerName: string,\n",
    "     EmailAddress: string,\n",
    "     Item: string,\n",
    "     Quantity: int,\n",
    "     UnitPrice: real,\n",
    "     TaxAmount: real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95c37db5-121c-4d29-ad1a-04bfbb3fef6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This command creates a table called **sales** with 9 columns of different data types.\n",
    "\n",
    "You can ingest data into a table in multiple ways, including the `ingest into` command, as shown in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9881f831-2756-4d6f-9c2d-da17f4c17a98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --kql\n",
    ".ingest into table sales 'https://<StorageAccountName>.blob.core.windows.net/container/<TableName>.csv' \n",
    " with (ignoreFirstRecord = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f7d6efa-1fe0-4c84-8e35-be862e40f5a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Retrieve data from a table\n",
    "A basic KQL query consists of selecting data from a table and applying filters and transformations to the data. In the following example, we're going to just query all the data from the `sales` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55d82f94-26d2-44ac-a7f1-95799648034f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql -kql\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d23e800f-efa3-4a36-b0e4-bdaff8601381",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The output from this query would look similar to the following example:\n",
    "\n",
    "| SalesOrderNumber | SalesOrderLineItem | OrderDate | CustomerName | EmailAddress | Item | Quantity | UnitPrice | TaxAmount |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| SO43701\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Christy Zhu\t  | christy12@adventure-works.com\t| Mountain-100 Silver 44\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| SO43704\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Julio Ruiz\t  | julio1@adventure-works.com\t| Mountain-100 Black 48\t| 1\t| 3374.99\t| 269.9992 |\n",
    "| SO43705\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Curtis Lu\t    | curtis9@adventure-works.com\t| Mountain-100 Silver 38\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| SO43700\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Ruben Prasad\t| ruben10@adventure-works.com\t| Road-650 Black 62\t| 1\t| 699.0982 | 55.9279 |\n",
    "| SO43703\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Albert Alvarez| albert7@adventure-works.com\t| Road-150 Red 62\t| 1\t| 3578.27\t| 286.2616 |\n",
    "| SO43697\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Cole Watson\t  | cole1@adventure-works.com\t| Road-150 Red 62\t| 1\t| 3578.27\t| 286.2616 |\n",
    "| SO43699\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Sydney Wright\t| sydney61@adventure-works.com\t| Mountain-100 Silver 44\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| ...\t| ...\t| ...\t| ...\t| ...\t| ...\t| ...\t| ...\t| ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43cb48fa-0c0b-462b-8982-88178e7e2fe4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The query output can then be further analyzed using visualization tools or integrated with other programs to create custom dashboards and automated workflows.\n",
    "\n",
    "The next example returns five rows from the sales table in the KQL database by using the `take` statement, which is a simple and quick way to view a small sample of records when browsing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "821f53ac-f94c-4c39-8605-accebb8e3a4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --kql\n",
    "sales\n",
    "| take 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1941b866-0583-4ad2-8f68-1390a4318b55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This time, the results include five rows:\n",
    "\n",
    "| SalesOrderNumber | SalesOrderLineItem | OrderDate | CustomerName | EmailAddress | Item | Quantity | UnitPrice | TaxAmount |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| SO43701\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Christy Zhu\t  | christy12@adventure-works.com\t| Mountain-100 Silver 44\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| SO43704\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Julio Ruiz\t  | julio1@adventure-works.com\t| Mountain-100 Black 48\t| 1\t| 3374.99\t| 269.9992 |\n",
    "| SO43705\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Curtis Lu\t    | curtis9@adventure-works.com\t| Mountain-100 Silver 38\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| SO43700\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Ruben Prasad\t| ruben10@adventure-works.com\t| Road-650 Black 62\t| 1\t| 699.0982 | 55.9279 |\n",
    "| SO43703\t          | 1\t                  | 2019-07-01T00:00:00Z\t    | Albert Alvarez| albert7@adventure-works.com\t| Road-150 Red 62\t| 1\t| 3578.27\t| 286.2616 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c8505db-7f1f-404e-a708-c9902aadcfac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Filter with the where clause\n",
    "In KQL, `where` is a clause that is used to filter the rows of a table based on a specified condition. The `where` clause is followed by a Boolean expression that evaluates to `true` or `false` for each row in the table. Rows for which the expression evaluates to `true` are included in the result, while rows for which the expression evaluates to `false` are excluded.\n",
    "\n",
    "The `contains` operator is used in the `where` clause of the query to filter the rows of the **_sales_** table based on whether the **Item** column contains the string \"Mountain-100\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6af2cae3-79a4-4068-82ff-55544aa0578b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --kql\n",
    "sales\n",
    "| where Item contains 'Mountain-100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c8faa56-16f5-45e8-b0a1-08da7ac2e78c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The results include only sales for items containing \"Mountain-100\":\n",
    "\n",
    "| SalesOrderNumber\t| SalesOrderLineItem\t| OrderDate\t| CustomerName\t| EmailAddress\t| Item\t| Quantity\t| UnitPrice\t| TaxAmount |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| SO43701\t| 1\t| 2019-07-01T00:00:00Z\t| Christy Zhu\t| christy12@adventure-works.com\t| Mountain-100 Silver 44\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| SO43704\t| 1\t| 2019-07-01T00:00:00Z\t| Julio Ruiz\t| julio1@adventure-works.com\t| Mountain-100 Black 48\t| 1\t| 3374.99\t| 269.9992 |\n",
    "| SO43705\t| 1\t| 2019-07-01T00:00:00Z\t| Curtis Lu\t| curtis9@adventure-works.com\t| Mountain-100 Silver 38\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| SO43699\t| 1\t| 2019-07-01T00:00:00Z\t| Sydney Wright\t| sydney61@adventure-works.com\t| Mountain-100 Silver 44\t| 1\t| 3399.99\t| 271.9992 |\n",
    "| ...\t| ...\t| ...\t| ...\t| ...\t| ...\t| ...\t| ...\t| ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23804f25-5350-437d-8a59-4a3b9030a11e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "KQL works well when you want to work with time series data. For example, to filter the sales data to show orders that occurred between two datetime values. You can take advantage of many time series functions, including `now()`, which returns the current time. This example returns all orders that occurred within the last day (24 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da80ed23-46be-4965-b00e-86734427c176",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --kql\n",
    "sales\n",
    "| where OrderDate between (now(-1d) .. now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "635a34b8-81e7-436b-86ef-52bfae239fb5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The results are filtered to include only orders within the specified time period.\n",
    "\n",
    "SalesOrderNumber\tSalesOrderLineItem\tOrderDate\tCustomerName\tEmailAddress\tItem\tQuantity\tUnitPrice\tTaxAmount\n",
    "SO49171\t1\t2023-05-01T22:01:00Z\tMariah Foster\tmariah21@adventure-works.com\tRoad-250 Black 48\t1\t2181.5625\t174.525\n",
    "SO49172\t1\t2021-05-01T23:55:00Z\tBrian Howard\tbrian23@adventure-works.com\tRoad-250 Red 44\t1\t2443.35\t195.468\n",
    "SO49173\t1\t2021-05-02T01:10:00Z\tLinda Alvarez\tlinda19@adventure-works.com\tMountain-200 Silver 38\t1\t2071.4196\t165.7136\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e75ecd0-021f-4795-84e7-f23abd3a2bef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Sort query results\n",
    "This query uses the `sort` operator to retrieve sales of \"Mountain-100\" items sorted so that the most recent sales are shown first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9ba949f-db59-44d6-ad63-a97147d2f576",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql -kql\n",
    "sales\n",
    "| where Item contains 'Mountain-100'\n",
    "| sort by OrderDate desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28d1b89c-b918-4d62-a117-70c3ef659ab9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The results look similar to this example:\n",
    "\n",
    "SalesOrderNumber\tSalesOrderLineItem\tOrderDate\tCustomerName\tEmailAddress\tItem\tQuantity\tUnitPrice\tTaxAmount\n",
    "SO43699\t1\t2023-05-01T00:00:00Z\tSydney Wright\tsydney61@adventure-works.com\tMountain-100 Silver 44\t1\t3399.99\t271.9992\n",
    "SO43705\t1\t2023-04-20T00:00:00Z\tCurtis Lu\tcurtis9@adventure-works.com\tMountain-100 Silver 38\t1\t3399.99\t271.9992\n",
    "SO43704\t1\t2023-04-12T00:00:00Z\tJulio Ruiz\tjulio1@adventure-works.com\tMountain-100 Black 48\t1\t3374.99\t269.9992\n",
    "SO43701\t1\t2023-03-27T00:00:00Z\tChristy Zhu\tchristy12@adventure-works.com\tMountain-100 Silver 44\t1\t3399.99\t271.9992\n",
    "...\t...\t...\t...\t...\t...\t...\t..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "902b82fe-5264-4326-8d5a-1421ff03393a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Summarize and aggregate\n",
    "You can use the `summarize` operator to group data by a column and create a new column with an aggregation for the group. For example, the following query returns the total quantity of each item that has sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e13d546-2769-4dbb-93db-f667e4a5d2fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --kql\n",
    "sales\n",
    "| summarize ItemsSold= sum(Quantity) by Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b1a7a4b-7494-4cbb-b9ac-5a53b87d75c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The results include a column based on the aggregation function used (in this case `sum()`)\n",
    "\n",
    "Item\tItemsSold\n",
    "Water Bottle - 30 oz.\t2,097\n",
    "Patch Kit/8 Patches\t1,621\n",
    "Mountain Tire Tube\t1,581\n",
    "Road Tire Tube\t1,212\n",
    "...\t..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d7e5c5b-7886-4a80-b328-17e4958025b1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using Copilot to assist with queryset queries\n",
    "One new feature within the Microsoft Real-Time Intelligence tooling is the ability to use [Copilot for Real-Time Intelligence](https://learn.microsoft.com/en-us/fabric/get-started/copilot-real-time-intelligence?branch=main). Copilot gives you the ability to write natural language prompts instead of writing or having to quickly learn KQL queries.\n",
    "\n",
    "When your administrator enables Copilot, you see the option in the top menubar of your querysets. When you ask a question about your data, Copilot will generate the KQL Code to answer your question. You can create several queries within the queryset using this no-code approach to gather useful information for user consumption.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/copilot.png\" alt=\"Nocode Copilot approach using Querysets\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "Once you have queries within the queryset, you can then Pin them to an existing dashboard or create a new dashboard. To accomplish this, select the queries you want pinned, and then select the **Pin to dashboard**. This gives you a window to perform other actions.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/copilot-pin-to-dashboard.png\" alt=\"Nocode Copilot Pin to dashboard\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "You also have the ability to add a queryset query to a Power BI Report by highlighting your preferred query and then selecting the **Build PowerBI report**.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/08/copilot-build-power-bi-report.png\" alt=\"Nocode Copilot Build PowerBI Report\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> You can only select one query at a time using the **Pin to Dashboard** or the **Build PowerBI report** but you can append dashboard elements to existing dashboards."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "08_Get started with Real-Time Intelligence in Microsoft Fabric",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
