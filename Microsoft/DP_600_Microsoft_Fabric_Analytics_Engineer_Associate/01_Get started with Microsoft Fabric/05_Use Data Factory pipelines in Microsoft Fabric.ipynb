{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05978be5-a1d2-4f88-8f07-9d4fed7bb564",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Understand Pipeline\n",
    "**Pipelines** in Microsoft Fabric encapsulate a **sequence of activities** that perform data movement and processing tasks. \n",
    "- You can use a pipeline to define **`data transfer`** and **`transformation activities`**, and orchestrate these activities through **`control flow activities`** that manage branching, looping, and other typical processing logic.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/05/pipeline.png\" alt=\"Pipeline\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8a28d9d-e9df-45a2-88c5-850e17802966",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Activities\n",
    "**Activities** are the **executable tasks** in a pipeline. \n",
    "- You can define a **flow of activities** by connecting them in a sequence. The outcome of a particular activity (success, failure, or completion) can be used to direct the flow to the next activity in the sequence.\n",
    "\n",
    "There are two broad categories of activity in a pipeline:\n",
    "1. **`Data transformation` activities:** activities that encapsulate **data transfer operations**, including:\n",
    "    - **Copy Data activities** that **_extract_** data from a source and **_load_** it to a destination\n",
    "    - **Data Flow activities** that encapsulate **`dataflows (Gen2)`** that **_apply_ transformations** to the data as it is transferred\n",
    "    - **Notebook activities** to run a **Spark notebook**\n",
    "    - **Stored procedure activities** to run **SQL code**\n",
    "    - **Delete data activities** to **_delete_** existing data\n",
    "    - and others.\n",
    "2. **`Control flow` activities:** activities that you can use to implement **loops**, **conditional branching**, or manage **variable** and **parameter** values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa22d47b-befd-49c7-93ea-2e95e305836d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> For details about the complete set of pipeline activities available in Microsoft Fabric, see [Activity overview](https://learn.microsoft.com/en-us/fabric/data-factory/activity-overview) in the Microsoft Fabric documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac45667b-c471-44b0-9c08-cac18c3c6fe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Parameters\n",
    "**Pipelines** can be **`parameterized`**, enabling you to **_provide_ specific values** to be used each time a pipeline is run. \n",
    "- Using parameters increases the **reusability** of your pipelines, enabling you to create **flexible** data ingestion and transformation processes.\n",
    "  - For example, you might want to use a pipeline to save ingested data in a folder, but have the flexibility to specify a folder name each time the pipeline is run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b9083cd-8771-4d1f-807f-868af3cec83a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pipeline runs\n",
    "Each time a pipeline is executed, a data **pipeline run** is initiated. \n",
    "- Runs can be initiated **on-demand** in the Fabric user interface or **scheduled** to start at a specific frequency. \n",
    "- Use the unique **`run ID`** to review run details to confirm they completed successfully and investigate the specific settings used for each execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c00aae58-187e-4d46-b87f-3e5391f2d722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Use the Copy Data activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9d38cbc-0f1d-4d21-97df-9d4b05e12a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The Copy Data tool\n",
    "When you add a **Copy Data activity** to a pipeline, a graphical tool takes you through the steps required to configure the **data source** and **destination** for the copy operation. \n",
    "- A wide range of source connections is supported, making it possible to ingest data from most common sources.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/05/copy-data.png\" alt=\"Copy Data\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41a0beb1-e952-41e7-8e4a-c30329a36023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Copy Data activity settings\n",
    "After you've added a Copy Data activity to a pipeline, you can select it in the pipeline canvas and edit its **settings** in the pane underneath.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/05/copy-data-activity.png\" alt=\"Copy Data activity\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef3755f5-37bb-434b-9e31-baeeb61301a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## When to use the Copy Data activity\n",
    "Use the **Copy Data activity** when you need:\n",
    "- to **copy data directly** between a supported source and destination **without applying any transformations**, or \n",
    "- to **import the raw data** and apply transformations in later pipeline activities.\n",
    "\n",
    "If you need to apply transformations to the data as it is ingested, or merge data from multiple sources, consider using a **`Data Flow activity`** to run a dataflow (Gen2). You can use the **Power Query** user interface to define a dataflow (Gen2) that includes multiple transformation steps, and include it in a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5254a978-b006-4181-a76c-430ec5cd1dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Run and monitor pipelines\n",
    "When you have completed a pipeline, you can use the **Validate** option to check that the configuration is valid, and then either run it interactively or specify a schedule.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/05/run-pipeline.png\" alt=\"Run Pipeline\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef4cdffb-df7d-455d-8e89-3af876db6bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## View run history\n",
    "You can view the run history for a pipeline to see details of each run, either from the pipeline canvas or from the pipeline item listed in the page for the workspace.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/05/pipeline-runs.png\" alt=\"Pipeline History Runs\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "When you view a pipeline run history from the workspace page, you can select the **Run start** value to see the details of an individual run; including the option to view the individual execution time for each activity as a Gantt chart.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/05/pipeline-run-details.png\" alt=\"Pipeline Runs Details\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Use Data Factory pipelines in Microsoft Fabric",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
