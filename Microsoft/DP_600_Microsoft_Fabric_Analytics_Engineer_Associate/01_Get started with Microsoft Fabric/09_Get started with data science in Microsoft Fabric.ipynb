{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d25dde8-3813-4656-b7bf-74c63b1ebdcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Understand the data science process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0965c5f8-acf0-407a-9420-ad12dca14e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Explore common machine learning models\n",
    "The purpose of machine learning is to train models that can identify patterns in large amounts of data. You can then use the patterns to make predictions that provide you with new insights on which you can take actions.\n",
    "\n",
    "The possibilities with machine learning may appear endless, so let's begin by understanding the four common types of machine learning models:\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/09/machine-learning-tasks.png\" alt=\"four common types of machine learning models\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "1. **Classification:** Predict a categorical value like whether a customer may churn.\n",
    "2. **Regression:** Predict a numerical value like the price of a product.\n",
    "3. **Clustering:** Group similar data points into clusters or groups.\n",
    "4. **Forecasting:** Predict future numerical values based on time-series data like the expected sales for the coming month.\n",
    "\n",
    "To decide which type of machine learning model you need to train, you first need to understand the business problem and the data available to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c732e98-0eac-44d6-8851-418b0121e7d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Understand the data science process\n",
    "To train a machine learning model, the process commonly involves the following steps:\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/09/data-science-process.png\" alt=\"sequential steps in the data science process\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "1. **Define the problem:** Together with business users and analysts, decide on what the model should predict and when it's successful.\n",
    "2. **Get the data:** Find data sources and get access by storing your data in a Lakehouse.\n",
    "3. **Prepare the data:** Explore the data by reading it from a Lakehouse into a notebook. Clean and transform the data based on the model's requirements.\n",
    "4. **Train the model:** Choose an algorithm and hyperparameter values based on trial and error by tracking your experiments with MLflow.\n",
    "5. **Generate insights:** Use model batch scoring to generate the requested predictions.\n",
    "\n",
    "\n",
    "As a data scientist, most of your time is spent on preparing the data and training the model. How you prepare the data and which algorithm you choose to train a model can influence your model's success.\n",
    "\n",
    "You can prepare and train a model by using open-source libraries available for the language of your choice. For example, if you work with Python, you can prepare the data with Pandas and Numpy, and train a model with libraries like [Scikit-Learn](https://scikit-learn.org/stable/), [PyTorch](https://pytorch.org/), or [SynapseML](https://microsoft.github.io/SynapseML/).\n",
    "\n",
    "When experimenting, you want to keep an overview of all the different models you've trained. You want to understand how your choices influence the model's success. By tracking your experiments with MLflow in Microsoft Fabric, you're able to easily manage and deploy the models you've trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa7f1258-2915-4eab-967d-fc5e23ccce93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Explore and process data with Microsoft Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d2d98ac-a9f3-439f-ac50-b23fa6bb8d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ingest your data into Microsoft Fabric\n",
    "To work with data in Microsoft Fabric, you first need to ingest data. You can ingest data from multiple sources, both local and cloud data sources. For example, you can ingest data from a CSV file stored on your local machine or in an Azure Data Lake Storage (Gen2).\n",
    "\n",
    "After connecting to a data source, you can save the data into a Microsoft Fabric **lakehouse**. You can use the lakehouse as a central location to store any structured, semi-structured, and unstructured files. You can then easily connect to the lakehouse whenever you want to access your data for exploration or transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b8d533a-39bd-4dae-9dfb-6992a8c5d75b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Explore and transform your data\n",
    "As a data scientist, you may be most familiar with writing and executing code in **notebooks**. Microsoft Fabric offers a familiar notebook experience, powered by Spark compute.\n",
    "\n",
    "**Apache Spark:** is an open source parallel processing framework for large-scale data processing and analytics.\n",
    "\n",
    "Notebooks are automatically attached to Spark compute. When you run a cell in a notebook for the first time, a new Spark session starts. The session persists when you run subsequent cells. The Spark session will automatically stop after some time of inactivity to save costs. You can also manually stop the session.\n",
    "\n",
    "When you're working in a notebook, you can choose the language you want to use. For data science workloads, you're likely to work with PySpark (Python) or SparkR (R).\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/09/notebooks.png\" alt=\"Screenshot of a notebook in Microsoft Fabric.\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "\n",
    "Within the notebook, you can explore your data using your preferred library, or with any of the built-in visualization options. If necessary, you can transform your data and save the processed data by writing it back to the lakehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "032edc5b-061b-4a79-9610-13b5ad6853e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prepare your data with the Data Wrangler\n",
    "To help you explore and transform your data more quickly, Microsoft Fabric offers the easy-to-use Data Wrangler.\n",
    "\n",
    "After launching the Data Wrangler, you'll get a descriptive overview of the data you're working with. You can view the summary statistics of your data to find any issues like missing values.\n",
    "\n",
    "To clean your data, you can choose any of the built-in data-cleaning operations. When you select an operation, a preview of the result and the associated code is automatically generated for you. When you have selected all necessary operations, you can export the transformations to code and execute it on your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8713da5b-6912-47d6-94ef-61ad5ee9ca20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Train and score models with Microsoft Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "340ee805-d798-49fc-9297-3c0039350499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Understand experiments\n",
    "Whenever you train a model in a notebook that you want to track, you create an experiment in Microsoft Fabric.\n",
    "\n",
    "An experiment can consist of multiple runs. Each run represents a task you executed in a notebook, like training a machine learning model.\n",
    "\n",
    "For example, to train a machine learning model for sales forecasting, you can try different training datasets with the same algorithm. Each time you train a model with a different dataset, you create a new experiment run. Then, you can compare the experiment runs to determine the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65d201c6-9d82-4bc6-9d9b-67744bf0f5bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Start tracking metrics\n",
    "To compare experiment runs, you can track parameters, metrics, and artifacts for each run.\n",
    "\n",
    "All parameters, metrics, and artifacts you track in an experiment run are shown in the experiments overview. You can view experiment runs individually in the Run details tab, or compare across runs with the Run list:\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/09/experiment.png\" alt=\"Screenshot of an experiment overview in Microsoft Fabric.\" style=\"border: 2px solid black; border-radius: 10px;\">\n",
    "\n",
    "By tracking your work with MLflow, you can compare model training iterations and decide which configuration resulted in the best model for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c069c73-d0fc-44c6-a57a-140565b7b11d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Understand models\n",
    "After you train a model, you want to use it for scoring. With scoring, you use the model on new data to generate predictions or insights. When you train and track a model with MLflow, artifacts are stored within the experiment run to represent your model and its metadata. You can save these artifacts in Microsoft Fabric as a model.\n",
    "\n",
    "By saving your model artifacts as a registered model in Microsoft Fabric, you can easily manage your models. Anytime you train a new model and save it under the same name, you add a new version to the model.\n",
    "\n",
    "<img src=\"../images/01_Get started with Microsoft Fabric/09/models.png\" alt=\"Screenshot of the model overview in Microsoft Fabric..\" style=\"border: 2px solid black; border-radius: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d60bf044-2709-4be9-ad9b-4089343a4b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use a model to generate insights\n",
    "To use a model for generating predictions, you can use the PREDICT function in Microsoft Fabric. The PREDICT function is built to easily integrate with MLflow models and allows you to use the model for generating batch predictions.\n",
    "\n",
    "For example, every week you receive sales data from several stores. Based on the historical data, you've trained a model that can predict the sales for the next week, based on the sales of the last few weeks. You tracked the model with MLflow and saved it in Microsoft Fabric. Whenever the new weekly sales data comes in, you use the PREDICT function to let the model generate the forecast for the next week. The forecasted sales data is stored as a table in a lakehouse, which is visualized in a Power BI report for business users to consume."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09_Get started with data science in Microsoft Fabric",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
