{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0b39fa2-cf21-4add-9aea-c389fa295f4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Understand Delta Lake\n",
    "**Delta Lake:** is an open-source **storage layer** that adds relational database semantics to Spark-based data lake processing. \n",
    "- Tables in Microsoft Fabric lakehouses are **`Delta tables`**, which is signified by the triangular Delta (â–´) icon on tables in the lakehouse user interface.\n",
    "\n",
    "![Delta Table](./images/09/delta-table.png)\n",
    "\n",
    "Delta tables are schema abstractions over data files that are stored in **Delta format**. \n",
    "- For each table, the lakehouse stores a folder containing **Parquet data file**s and **`a _delta_Log`** folder in which transaction details are logged in JSON format.\n",
    "\n",
    "![Parquet files](./images/09/delta-files.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb5eae65-b956-448b-8227-0d9bbe6c2f3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Benefits\n",
    "The benefits of using Delta tables include:\n",
    "\n",
    "- **Relational tables that support `querying` and data `modification`.** \n",
    "  - With Apache Spark, you can store data in Delta tables that support **CRUD (create, read, update, and delete)** operations. \n",
    "- **Support for `ACID transactions`.** \n",
    "  - Relational databases are designed to support transactional data modifications that provide:\n",
    "    - **`A`** tomicity (transactions complete as a single unit of work)\n",
    "    - **`C`** onsistency (transactions leave the database in a consistent state)\n",
    "    - **`I`** solation (in-process transactions can't interfere with one another)\n",
    "    - **`D`** urability (when a transaction completes, the changes it made are persisted). \n",
    "  - Delta Lake brings this same transactional support to Spark by implementing a transaction log and enforcing serializable isolation for concurrent operations.\n",
    "- **`Data versioning` and `time travel`.** \n",
    "  - Because all transactions are logged in the **`transaction log`**, you can **track multiple versions** of each table row and even use the time travel feature to **retrieve a previous version** of a row in a query.\n",
    "- **Support for `batch` and `streaming` data.** \n",
    "  - While most relational databases include tables that store static data, Spark includes native support for streaming data through the **Spark Structured Streaming API**. Delta Lake tables can be used as both sinks (destinations) and sources for streaming data.\n",
    "- **Standard formats and interoperability.** \n",
    "  - The underlying data for Delta tables is stored in Parquet format, which is commonly used in data lake ingestion pipelines. Additionally, you can use the **`SQL analytics endpoint`** for the Microsoft Fabric lakehouse to query Delta tables in SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59429378-f755-4a43-8968-d49acb1ee6df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create delta tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "018eaa97-43e1-4273-ae52-07bc7a05ebd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Work with delta tables in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "506962f4-f2c8-4721-9293-db0747fca200",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Use delta tables with streaming data"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09_Work with Delta Lake tables in Microsoft Fabric",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
