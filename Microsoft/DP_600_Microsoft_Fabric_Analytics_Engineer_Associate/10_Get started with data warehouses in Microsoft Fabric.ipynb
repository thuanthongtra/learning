{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0b39fa2-cf21-4add-9aea-c389fa295f4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Understand data warehouse fundamentals\n",
    "The process of building a modern data warehouse typically consists of:\n",
    "- **Data ingestion** - **`moving`** data from source systems into a data warehouse.\n",
    "- **Data storage** - **`storing`** the data in a format that is optimized for analytics.\n",
    "- **Data processing** - **`transforming`** the data into a format that is ready for consumption by analytical tools.\n",
    "- **Data analysis and delivery** - **`analyzing`** the data to gain insights and delivering those insights to the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7e3a546-4e08-4cff-b6f1-37f9eb07d8ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Understand Fabric's data warehouse experience\n",
    "**Fabric's data warehouse:** \n",
    "- Is a **`relational data warehouse`** that supports the full transactional T-SQL capabilities you'd expect from an enterprise data warehouse. \n",
    "- It's a fully managed, scalable, and highly available data warehouse that can be used to store and query data in the **`Lakehouse`**. \n",
    "  - Using the data warehouse, you're fully in control of creating tables, loading, transforming, and querying data using either the Fabric portal or T-SQL commands. \n",
    "  - You can use SQL to query and analyze the data, or use Spark to process the data and create machine learning models.\n",
    "\n",
    "Data warehouses in Fabric facilitate collaboration between data engineers and data analysts, working together in the same experience. \n",
    "- Data engineers build a relational layer on top of data in the Lakehouse, where analysts can use T-SQL and Power BI to explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0497b45d-f845-455b-a953-2402b3a19ceb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Design a data warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "282a14b9-d803-4869-9302-4e2b5b9ffef3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Tables in a data warehouse\n",
    "Tables in a data warehouse are typically organized in **`dimensional modeling`**, which involves structuring tables into **`fact tables`** and **`dimension tables`**.\n",
    "\n",
    "**1. Fact tables:** contain the **`numerical data`** that you want to analyze. \n",
    "- Fact tables typically have a **large number** of rows and are the **primary source** of data for analysis. \n",
    "- For example, a fact table might contain the total amount paid for sales orders that occurred on a specific date or at a particular store.\n",
    "\n",
    "**2. Dimension tables:** contain **`descriptive information`** about the data in the fact tables.\n",
    "- Dimension tables typically have a **small number of rows** and are used to **provide context** for the data in the fact tables. \n",
    "- For example, a dimension table might contain information about the customers who placed sales orders.\n",
    "\n",
    "It's common for a dimension table to include two key columns:\n",
    "\n",
    "**1. A surrogate key:** is a unique identifier for each row in the dimension table. \n",
    "- It's often an integer value that is **`automatically generated`** by the database management system when a new row is inserted into the table.\n",
    "- Surrogate keys are specific to the data warehouse and help to maintain consistency and accuracy in the data. \n",
    "\n",
    "**2. An alternate key:** is often a **`natural or business key`** that identifies a specific instance of an entity in the transactional source system - such as a product code or a customer ID.\n",
    "- Alternate keys on the other hand are specific to the source system and help to maintain traceability between the data warehouse and the source system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2443b6d-784c-46eb-8d92-6a2f48a3c4c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Special types of dimension tables\n",
    "Special types of dimensions provide additional context and enable more comprehensive data analysis.\n",
    "\n",
    "**Time dimensions:** provide information about the **`time period`** in which an event occurred. \n",
    "- This table enables data analysts to aggregate data over temporal intervals. \n",
    "- For example, a time dimension might include columns for the year, quarter, month, and day in which a sales order was placed.\n",
    "\n",
    "**Slowly changing dimensions:** are dimension tables that **`track changes`** to dimension attributes over time, like changes to a customer's address or a product's price. \n",
    "- They're significant in a data warehouse because they enable users to analyze and understand **changes to data over time**. \n",
    "- Slowly changing dimensions ensure that data stays up-to-date and accurate, which is imperative to making good business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f42f771-23f2-44b1-952d-45e0e3d190a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data warehouse schema designs\n",
    "In a data warehouse however, the dimension data is generally **`de-normalized`** to **reduce the number of joins** required to query the data.\n",
    "\n",
    "**1. Star Schema:** Often, a data warehouse is organized as a **`star schema`**, in which a fact table is directly related to the dimension tables, as shown in this example:\n",
    "\n",
    "![Star Schema](./images/10/star-schema.png)\n",
    "\n",
    "You can use the attributes of something to group together numbers in the fact table at different levels. For example, you could find the total sales revenue for a whole region or just for one customer. The information for each level can be stored in the same dimension table.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> See [What is a star schema?](https://learn.microsoft.com/en-us/power-bi/guidance/star-schema) for more information on designing star schemas for Fabric.\n",
    "\n",
    "**2. Snowflake:**\n",
    "If there are lots of levels or some information is shared by different things, it might make sense to use a **`snowflake`** schema instead. Here's an example:\n",
    "\n",
    "![Snowflake](./images/10/snowflake-schema.png)\n",
    "\n",
    "In this case, \n",
    "- The **DimProduct** table has been **`split up (normalized)`** to create separate dimension tables for product categories and suppliers.\n",
    "  - Each row in the **DimProduct** table contains key values for the corresponding rows in the **DimCategory** and **DimSupplier** tables.\n",
    "- A **DimGeography** table has been **`added`** containing information on where customers and stores are located.\n",
    "  - Each row in the **DimCustomer** and **DimStore** tables contains a key value for the corresponding row in the **DimGeography** table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd4ad53-64a9-4384-8701-5fc1710ab9db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Understand data warehouses in Fabric\n",
    "- **Fabric's Lakehouse:** is a collection of files, folders, tables, and shortcuts that act like a database over a **`data lake`**.\n",
    "- **Fabric's data warehouse:** experience allows you to transition from the lake view of the Lakehouse (which supports data engineering and Apache Spark) to the **SQL experiences** that a traditional data warehouse would provide. \n",
    "- The **Lakehouse** gives you the ability to **`read`** tables and use the SQL analytics endpoint, whereas the **data warehouse** enables you to **`manipulate`** the data.\n",
    "- In the data warehouse experience, you'll:\n",
    "  - **model** data using tables and views\n",
    "  - run T-SQL to **query data** across the data warehouse and Lakehouse\n",
    "  - use T-SQL to **perform DML operations** on data inside the data warehouse\n",
    "  - **serve** reporting layers like Power BI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbeed8ce-8b70-4150-a2ae-2051753ec9d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Describe a data warehouse in Fabric\n",
    "In the data warehouse experience in Fabric, you can build a **relational layer** on top of **physical data** in the Lakehouse and expose it to analysis and reporting tools. \n",
    "- You can create your data warehouse directly in Fabric from the **`create hub`** or within a **`workspace`**. After creating an empty warehouse, you can add objects to it.\n",
    "- Once your warehouse is created, you can create tables using T-SQL directly in the Fabric interface.\n",
    "\n",
    "![Create Date Warehouse](./images/10/create-data-warehouse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b28baf4-c4f1-48fb-bd3a-551a0741601b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Ingest data into your data warehouse\n",
    "There are a few ways to ingest data into a Fabric data warehouse, including **Pipelines**, **Dataflows**, **cross-database querying**, and the **`COPY INTO`** command**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b537353-0d18-46c6-a7b3-86e7e4649321",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create tables\n",
    "To create a table in the data warehouse, you can use **SQL Server Management Studio (SSMS)** or another **SQL client** to connect to the data warehouse and run a **`CREATE TABLE`** statement. You can also create tables directly in the Fabric UI.\n",
    "\n",
    "You can copy data from an external location into a table in the data warehouse using the **`COPY INTO`** syntax. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdf2c002-7da1-4ba6-b71d-44e3694107d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "COPY INTO dbo.Region \n",
    "FROM 'https://mystorageaccountxxx.blob.core.windows.net/private/Region.csv' WITH ( \n",
    "            FILE_TYPE = 'CSV'\n",
    "            ,CREDENTIAL = ( \n",
    "                IDENTITY = 'Shared Access Signature'\n",
    "                , SECRET = 'xxx'\n",
    "                )\n",
    "            ,FIRSTROW = 2\n",
    "            )\n",
    "GO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b25d211-4e2a-44fd-8266-fb812cb78098",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This SQL query loads data from a CSV file stored in Azure Blob Storage into a table called \"Region\" in the Fabric data warehouse.\n",
    "\n",
    "![Create Table](./images/10/create-table-manual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45e587fa-f88a-43a7-98ee-70540bedf0e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Table considerations\n",
    "**1. Staging tables:** are temporary tables that can be used to perform **data `cleansing`**, **data `transformations`**, and **data `validation`**.\n",
    "- After creating tables in a data warehouse, it's important to consider the process of loading data into those tables. A common approach is to use **`staging tables`**\n",
    "  - In Fabric, you can use T-SQL commands to load data from files into staging tables in the data warehouse.\n",
    "  - You can also use staging tables to load data from multiple sources into a **single destination table**.\n",
    "\n",
    "**2. Time interval:** Usually, data loading is performed as a **`periodic batch process`** in which inserts and updates to the data warehouse are coordinated to occur at a **`regular interval`** (for example, daily, weekly, or monthly).\n",
    "\n",
    "**3. Steps:** Generally, you should implement a data warehouse load process that performs tasks in the following order:\n",
    "1. Ingest the new data to be loaded into a **data lake**, applying **pre-load `cleansing`** or **`transformations`** as required.\n",
    "2. Load the data from files into **`staging tables`** in the relational data warehouse.\n",
    "3. Load the **`dimension tables`** from the dimension data in the **staging tables**, **updating** existing rows or **inserting** new rows and **generating `surrogate`** key values as necessary.\n",
    "4. Load the **`fact tables`** from the fact data in the **staging tables**, looking up the appropriate **`surrogate`** keys for related dimensions.\n",
    "5. Perform post-load optimization by **updating** **`indexes`** and table **`distribution statistics`**.\n",
    "\n",
    "If you have tables in the lakehouse, and you want to be able to query it in your warehouse - but not make changes - with a Fabric data warehouse, you don't have to copy data from the lakehouse to the data warehouse. You can query data in the lakehouse directly from the data warehouse using cross-database querying.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Working with tables in the Fabric data warehouse currently has some limitations. See [Tables in data warehousing in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-warehouse/tables) for more information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec1b2ce4-6843-43ac-9784-5e338a6acbad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Query and transform data\n",
    "There are two ways to query data from your data warehouse:\n",
    "\n",
    "**1. The Visual query editor:** provides a **no-code**, drag-and-drop experience to create your queries. \n",
    "\n",
    "**2. SQL query editor:** to write **T-SQL** queries. \n",
    "\n",
    "In both cases, you can create tables, views, and stored procedures to query data in the data warehouse and Lakehouse.\n",
    "\n",
    "There's also a **`SQL analytics endpoint`**, where you can connect from any tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6998c4cf-33dd-4573-b1f6-af9d00d68548",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Visual query editor\n",
    "**The Visual query editor:** provides an experience similar to the [Power Query online diagram view](https://learn.microsoft.com/en-us/power-query/diagram-view). \n",
    "- Use the **New visual query button** to create a new query.\n",
    "- Drag a table from your data warehouse onto the canvas to get started. You can then use the **Transform** menu at the top of the screen to add columns, filters, and other transformations to your query. \n",
    "- You can use the (+) button on the visual itself to perform similar transformations.\n",
    "\n",
    "![Visual Query Editor](./images/10/visual-query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4016396e-6519-400b-b153-0a37d205c2d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query data using the SQL query editor\n",
    "**The SQL query editor:** provides a query experience that includes intellisense, code completion, syntax highlighting, client-side parsing, and validation. If you've written T-SQL in SQL Server Management Studio (SSMS) or Azure Data Studio (ADS), you'll find it familiar.\n",
    "- To create a new query, use the **New SQL query button** in the menu. \n",
    "- You can author and run your T-SQL queries here. In the example below we're creating a new view for analysts to use for reporting in Power BI.\n",
    "\n",
    "![SQL Query Editor](./images/10/create-view.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01fb93e7-8eb1-4b51-b8b6-5e8fb9ea1408",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Prepare data for analysis and reporting\n",
    "You can easily switch between the **Data**, **Query**, and **Model** view Fabric using the menu in the bottom left corner of the screen. \n",
    "- The **Data** view shows the **`tables`** in the semantic model\n",
    "- The **Query** view shows the **`SQL queries`** that are used to create the semantic model\n",
    "- The **Model** view shows the **`semantic model`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf5cff80-969e-478c-afd5-cd7900d09034",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Semantic model\n",
    "- Every time a **data warehouse** is **`created`**, Fabric **`creates`** a **semantic model** for analysts and/or business users to connect to for reporting.\n",
    "- **Semantic models** are automatically kept in **`sync`** with the **data warehouse**, so you don't have to worry about maintaining them. You can also create **`custom` semantic models** to meet your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8b24276-3481-4ebb-9987-9e1a98feb955",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Understand semantic models\n",
    "**A semantic model:** defines \n",
    "- The **`relationships`** between the different tables in the semantic model, \n",
    "- The **`rules`** for how data is aggregated and summarized, and \n",
    "- The **`calculations`** or **`measures`** that are used to derive insights from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff232166-94b8-4516-8043-6452df704d71",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Understand the default semantic model\n",
    "There's also a **`default` semantic model** automatically created for you in Fabric. \n",
    "- It **inherits** business logic from the parent lakehouse or warehouse, which initiates the downstream analytics experience for business intelligence and analysis. This semantic model is **managed**, **optimized**, and **kept in sync** for you.\n",
    "- New tables in the Lakehouse are **automatically added** to the default semantic model.\n",
    "  - Users can also manually select tables or views from the warehouse they want included in the model for more flexibility.\n",
    "  - Objects that are in the default semantic model are created as a layout in the model view.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Default semantic models follow the current limitations for semantic models in Power BI. See [Default Power BI semantic models](https://learn.microsoft.com/en-us/fabric/data-warehouse/limitations) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40ee3e32-b53c-4a53-b623-b9c1bd6c7c78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Build relationships\n",
    "**Relationships** allow you to **`connect tables`** in the semantic model. Create relationships between tables in your data warehouse using a click-and-drag interface in Fabric in the **Model** view.\n",
    "\n",
    "![Fabric displaying relationships](./images/10/create-relationships.png)\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> See [Create and manage relationships](https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-create-and-manage-relationships) for detailed information on creating relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8386d0fe-9a39-4c72-8da8-3e2c08e6fa16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create measures\n",
    "**Measures** are the **metrics** that you want to **`analyze`** in your data warehouse. You can create measures in Fabric by using the New measure button in the **Model** view.\n",
    "- Measures are calculated fields that are based on the data in the tables in your data warehouse using the **Data Analysis Expressions (DAX)** formula language.\n",
    "\n",
    "![Fabric displaying the new measure](./images/10/create-measure.png)\n",
    "\n",
    "Fabric offers many tools to create data transformations. The creation of measures using DAX is one of many ways to create data transformations. To learn more about DAX, see [Use DAX in Power BI](https://learn.microsoft.com/en-us/training/paths/dax-power-bi/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aef4eb88-3835-413d-ad85-ca6340b33ee0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Hide fields\n",
    "Building out the semantic model is a critical component to preparing your data for use in downstream reporting. To simplify things for your report builders, you can **`hide elements`** from **view**, either a **table** or a **column**. Right-click on the table or column and select **Hide**. \n",
    "- Hiding fields removes the table or column from the **model view**, but it will still be available for use in the semantic model.\n",
    "\n",
    "![Hidden fields](./images/10/hide-fields.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7507d4d-bd7f-4ba5-8b2b-d58f76157cb7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Visualize data\n",
    "Fabric enables you to **`visualize`** the results of a **single query** or your **entire data warehouse**, without leaving the data warehouse experience.\n",
    "\n",
    "Use the **New report** button to create a new Power BI report from the contents of your entire data warehouse. Using the **New report** button opens the Power BI service experience where you can build and save your report for use by the business.\n",
    "\n",
    "![Power BI report](./images/10/sales-report.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bc502de-30ce-451a-8b66-594c053e0fa2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Secure and monitor your data warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2ab3e47-4f16-44da-846a-0156af8c5dab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Security\n",
    "**Data warehouse security:** is important to protect your data from unauthorized access. Fabric provides a number of security features to help you secure your data warehouse. These include:\n",
    "\n",
    "- **Role-based access control (RBAC):** to **control `access`** to the warehouse and its data.\n",
    "- **SSL encryption:** to **secure** the **`communication`** between the **warehouse** and the **client applications**.\n",
    "- **Azure Storage Service Encryption:** to **protect** the **`data`** in transit and at rest.\n",
    "- **Azure Monitor and Azure Log Analytics:** to **monitor** the warehouse **`activity`** and **`audit`** the access to the data.\n",
    "- **Multifactor authentication (MFA):** to **add** an **`extra layer`** of security to user accounts.\n",
    "- **Microsoft Entra ID integration:** to **manage** the user **`identities`** and **`access`** to the warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd843b92-e40f-4705-b876-4e0cc5838db5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Workspace permissions\n",
    "Data in Fabric is organized into **workspaces**, which are used to \n",
    "- **control `access`** and \n",
    "- **manage** the **`lifecycle of data`** and **`services`**. \n",
    "\n",
    "Appropriate **`workspace roles`** are the **`first` line of defense** in securing your data warehouse.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> See [Workspaces in Power BI](https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-new-workspaces#roles-and-licenses) for more information on workspace roles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17fc5a39-3aa8-4d2f-8a3e-f4c93d3de31f",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Item permissions\n",
    "In contrast to **`workspace` roles**, which apply to **`all` items** within a workspace, you can use **`item` permissions** to grant access to **`individual` warehouses**. \n",
    "- This enables you to share a single data warehouse for downstream consumption.\n",
    "- You can grant permissions to users via T-SQL or in the Fabric portal. \n",
    "\n",
    "Grant the following permissions to users who need to access your data warehouse:\n",
    "\n",
    "- **Read:** Allows the user to **connect** using the SQL connection string.\n",
    "- **ReadData:** Allows the user to **read** data from any **`table/view`** within the warehouse.\n",
    "- **ReadAll:** Allows user to **read** data the **`raw parquet files`** in OneLake that can be consumed by Spark.\n",
    "\n",
    "A user connection to the **`SQL analytics endpoint`** will **fail without `Read` permission** at a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adf49626-e915-4da8-ab87-d46a9c971196",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Monitoring\n",
    "**Monitoring activities** in your data warehouse is crucial to:\n",
    "- Ensure optimal performance, efficient resource utilization, and security.\n",
    "- Identify issues, detect anomalies, and take action to keep the data warehouse running smoothly and securely.\n",
    "\n",
    "You can use **`dynamic management views (DMVs)`** to monitor connection, session, and request status to see live SQL query lifecycle insights. There are currently three DMVs available to use in Fabric:\n",
    "\n",
    "- **`sys.dm_exec_connections`:** Returns information about each **`connection`** established between the warehouse and the engine.\n",
    "- **`sys.dm_exec_sessions`:** Returns information about each **`session`** authenticated between the item and engine.\n",
    "- **`sys.dm_exec_requests`:** Returns information about each active **`request`** in a session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff75d359-4cd4-4e65-bcd2-7a456502f931",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Query monitoring\n",
    "Use 'sys.dm_exec_requests' to identify long-running queries that may be impacting the overall performance of the database, and take appropriate action to optimize or terminate those queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fd15a90-8273-4e60-a27c-e77234d8c9d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Start by identifying the queries that have been running for a long time. Use the following query to identify which queries have been running the longest, in descending order:\n",
    "SELECT request_id, session_id, start_time, total_elapsed_time\n",
    "    FROM sys.dm_exec_requests\n",
    "    WHERE status = 'running'\n",
    "    ORDER BY total_elapsed_time DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf729447-dc3b-45e6-944d-5ace5dd3c067",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- You can continue investigating to understand which user ran the session with the long-running query, by running:\n",
    "SELECT login_name\n",
    "    FROM sys.dm_exec_sessions\n",
    "    WHERE 'session_id' = 'SESSION_ID WITH LONG-RUNNING QUERY';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d4c8751-5e78-440f-bae3-27ff8e37e4c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Finally, you can use the KILL command to terminate the session with the long-running query:\n",
    "KILL 'SESSION_ID WITH LONG-RUNNING QUERY';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02041f53-2677-4fdf-a6d9-8eb99ce953a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> You must be a workspace Admin to run the `KILL` command. Workspace Admins can execute all three DMVs. Member, Contributor, and Viewer roles can see their own results within the warehouse, but cannot see other users' results."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10_Get started with data warehouses in Microsoft Fabric",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
